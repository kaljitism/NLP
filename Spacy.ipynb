{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Hello World!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "World\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hello World!"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "span = doc[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'World!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(\"This framework is spacy, isnt it beautiful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Text:  ['This', 'framework', 'is', 'spacy', ',', 'is', 'nt', 'it', 'beautiful', '!']\n"
     ]
    }
   ],
   "source": [
    "print(\"Index: \", [token.i for token in doc1])\n",
    "print(\"Text: \", [token.text for token in doc1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_alpha:  [True, True, True, True, False, True, True, True, True, False]\n"
     ]
    }
   ],
   "source": [
    "print(\"is_alpha: \", [token.is_alpha for token in doc1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_punct:  [False, False, False, False, True, False, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "print(\"is_punct: \", [token.is_punct for token in doc1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like_num:  [False, False, False, False, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "print(\"like_num: \", [token.like_num for token in doc1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "# \"\"\"\n",
    "# It includes Binary weights, Vocab, Meta Information like Language, pipeline\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('She ate the Pizza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She PRON\n",
      "ate VERB\n",
      "the DET\n",
      "Pizza PROPN\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She PRON nsubj ate\n",
      "ate VERB ROOT ate\n",
      "the DET det Pizza\n",
      "Pizza PROPN dobj ate\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_, token.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Apple is looking for buying an Indian startup in $1 Billion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "Indian NORP\n",
      "$1 Billion MONEY\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nationalities or religious or political groups'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('NORP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun, proper singular'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('NNP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'direct object'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"dobj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nominal subject'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('nsubj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{'ORTH': 'iPhone'}, {'ORTH': 'X'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('IPHONE_PATTERN', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"New iPhone X release date is leaked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9528407286733565721, 1, 3)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone X\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [\n",
    "    {'IS_DIGIT': True},\n",
    "    {'LOWER': 'fifa'},\n",
    "    {'LOWER': 'world'},\n",
    "    {'LOWER': 'cup'},\n",
    "    {'IS_PUNCT': True}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"2018 FIFA World Cup: France Won!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    " matcher.add('NEWS_PATTERN', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 FIFA World Cup:\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [\n",
    "    {'LEMMA': 'love', 'POS': 'VERB'},\n",
    "    {'POS': 'NOUN'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('PET_LOVE', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I love elephant, then I used to love dogs but now I love cats\")\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love elephant\n",
      "love dogs\n",
      "love cats\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Structures: Vocab, Lexems, and String Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffe_hash = nlp.vocab.strings['coffee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3197928453018144401"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffe_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert coffe_hash == 3197928453018144401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('I love coffee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexeme = nlp.vocab['coffee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('coffee', 3197928453018144401, True, False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexeme.text, lexeme.orth, lexeme.is_alpha, lexeme.is_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"Hello\", \"World\", \"!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaces = [True, False, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Doc(nlp.vocab, words=words, spaces=spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hello World!"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "span = Span(doc, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hello World"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_with_label = Span(doc, 0, 2, label=\"Greet!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Greet!'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_with_label.label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_with_label.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hello World"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_with_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(\"Hello World!\")\n",
    "doc2 = nlp(\"Hey Everyone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8568477490597306"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I like Pizza\")\n",
    "token = nlp(\"Soap\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32531983166759537\n"
     ]
    }
   ],
   "source": [
    "print(doc.similarity(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "span = nlp(\"I like pizza and pasta\")[2:3]\n",
    "doc = nlp(\"McDonals sells burgers\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7089699\n"
     ]
    }
   ],
   "source": [
    "print(span.similarity(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1a = nlp(\"Man\")\n",
    "class2a = nlp(\"King\")\n",
    "\n",
    "class1b = nlp(\"Woman\")\n",
    "class2b = nlp(\"Queen\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Man - Woman =  0.7401743668099329\n",
      "King - Queen =  0.7252610345406867\n"
     ]
    }
   ],
   "source": [
    "print(\"Man - Woman = \", class1a.similarity(class1b))\n",
    "print(\"King - Queen = \", class2a.similarity(class2b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I have a mango!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0779204 ,  0.2576558 , -0.037042  , -0.151036  ,  0.08673356,\n",
       "        0.02067319,  0.1777344 , -0.3452856 ,  0.0527916 ,  1.5635926 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vector[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.39086  ,  0.33664  ,  0.62282  , -0.14561  ,  0.089456 ,\n",
       "        0.66506  ,  0.18482  , -0.3824   ,  0.21445  ,  0.054463 ,\n",
       "       -0.4647   ,  0.067074 , -1.0379   , -0.29004  ,  0.023828 ,\n",
       "       -0.092388 , -0.0023503,  0.98985  ,  0.37535  , -0.13404  ,\n",
       "        0.11986  ,  0.65159  ,  0.15408  ,  0.71978  , -0.32733  ,\n",
       "       -0.5124   ,  0.050161 ,  0.042919 ,  0.094624 , -0.89656  ,\n",
       "       -0.0084081, -0.40156  ,  0.26622  , -0.5297   , -0.33762  ,\n",
       "        0.19521  ,  0.15476  , -0.039438 , -1.0185   ,  0.24024  ,\n",
       "       -0.35842  ,  0.020426 ,  0.0086298, -0.087828 ,  0.21932  ,\n",
       "        0.86854  , -0.31764  ,  0.49903  ,  0.22552  ,  0.36338  ,\n",
       "        0.12186  , -0.35134  ,  0.17495  ,  0.015455 ,  1.0356   ,\n",
       "       -0.72409  ,  0.018939 , -0.095863 , -0.1387   , -0.092748 ,\n",
       "        0.090583 , -0.4015   , -0.045474 ,  0.35143  ,  0.15385  ,\n",
       "       -0.48643  , -0.023118 , -0.2167   , -0.31057  ,  0.60142  ,\n",
       "       -0.10843  ,  0.71502  , -0.15498  ,  0.51862  ,  0.24765  ,\n",
       "        0.062018 ,  0.34098  ,  0.03768  , -0.38138  , -0.61405  ,\n",
       "        0.25635  , -0.019619 , -0.10214  ,  0.10405  , -0.19426  ,\n",
       "       -0.063548 ,  0.94613  ,  0.53859  , -0.99649  , -0.23616  ,\n",
       "        0.10187  , -0.064976 ,  0.22709  ,  0.2968   , -0.77662  ,\n",
       "        0.81697  ,  0.011388 , -0.24175  , -0.78068  ,  0.43864  ,\n",
       "        0.68721  , -0.2466   ,  0.31766  , -0.28975  , -0.63729  ,\n",
       "       -1.1436   ,  0.23705  , -0.08647  ,  1.0307   ,  0.17032  ,\n",
       "       -0.21947  , -0.59674  , -0.67498  , -0.042711 , -0.11685  ,\n",
       "        0.34167  ,  0.35302  ,  0.11676  ,  0.38666  ,  0.23031  ,\n",
       "       -0.3695   ,  0.4511   , -0.37987  , -0.16466  ,  0.025379 ,\n",
       "        0.010775 ,  0.20839  , -0.18015  , -0.39021  , -0.034611 ,\n",
       "       -0.32715  , -0.73323  , -0.19621  ,  0.43878  , -0.42313  ,\n",
       "       -0.25807  ,  0.099825 , -0.36085  ,  0.042282 ,  0.10418  ,\n",
       "       -1.9119   ,  0.59419  ,  0.29671  ,  0.19129  ,  0.10451  ,\n",
       "       -0.02527  ,  0.077357 ,  0.62055  , -0.10214  , -0.38108  ,\n",
       "        0.31821  ,  0.18837  ,  0.38734  ,  0.29772  , -0.5558   ,\n",
       "       -0.51838  ,  0.2608   , -0.36136  ,  0.35201  ,  0.38861  ,\n",
       "        0.21179  ,  0.63004  ,  0.36778  ,  0.12043  ,  0.11746  ,\n",
       "       -0.048625 , -0.20438  , -0.37703  ,  0.070052 ,  0.22903  ,\n",
       "       -0.12949  ,  0.065959 , -0.15734  ,  0.0070423, -0.93405  ,\n",
       "       -0.12101  ,  0.031429 , -0.46016  ,  0.28032  , -1.0008   ,\n",
       "       -0.089948 ,  0.056399 , -0.067933 , -0.34919  ,  0.23737  ,\n",
       "       -0.56814  , -0.13111  , -0.35805  ,  0.075294 , -0.054791 ,\n",
       "       -0.6576   , -0.1112   , -0.24472  , -0.27189  , -0.56202  ,\n",
       "       -0.22643  ,  0.60548  ,  0.35436  , -0.44618  ,  0.255    ,\n",
       "       -0.60371  ,  0.028117 ,  0.18453  ,  0.45185  , -0.10035  ,\n",
       "        0.03962  ,  0.23721  ,  0.6885   ,  0.2614   ,  0.51478  ,\n",
       "       -0.0035348,  0.30721  ,  0.1634   ,  0.042499 , -0.58242  ,\n",
       "       -0.14283  , -0.53144  , -0.50574  ,  0.076523 , -0.37139  ,\n",
       "       -0.93162  , -0.0079317,  0.6478   ,  0.48952  ,  0.39838  ,\n",
       "       -0.042727 , -0.4395   ,  0.020771 , -0.16104  ,  0.05258  ,\n",
       "       -0.33976  , -0.25678  , -0.35705  ,  0.16782  , -0.44162  ,\n",
       "       -0.74528  ,  0.21144  , -0.54955  ,  0.55068  ,  0.35139  ,\n",
       "       -0.2766   , -0.49113  , -0.60975  , -0.51003  ,  0.22702  ,\n",
       "       -0.10112  ,  0.62345  , -0.18344  ,  0.034892 ,  0.28107  ,\n",
       "       -0.28012  , -0.006337 , -0.47978  ,  0.20596  ,  0.27621  ,\n",
       "        0.60099  ,  0.33575  , -0.21852  ,  0.17493  , -0.40076  ,\n",
       "        0.4363   , -0.27091  , -0.37562  ,  0.21075  , -0.13184  ,\n",
       "       -0.27795  , -0.10921  ,  0.13667  , -0.58417  , -0.084237 ,\n",
       "       -0.011812 ,  0.19565  , -0.18861  ,  0.079701 ,  0.16454  ,\n",
       "        0.26489  ,  0.17643  ,  0.33779  , -0.19154  ,  0.44671  ,\n",
       "        0.05724  ,  0.27456  ,  0.22276  ,  0.14017  ,  0.55124  ,\n",
       "        0.20947  , -0.0069308,  0.33561  ,  0.03615  , -0.50204  ,\n",
       "        0.15664  ,  0.1776   , -0.27161  , -0.13589  , -0.14053  ,\n",
       "        0.52206  ,  0.33456  , -1.0113   , -0.08825  ,  0.51987  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[3].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(\"I like cats\")\n",
    "doc2 = nlp(\"I hate cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9501446702124066"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched span: golden retriever\n",
      "Root token: retriever\n",
      "Root head token: have\n",
      "Previous token: a DET\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('DOG', None, [{'LOWER': 'golden'}, {'LOWER': 'retriever'}])\n",
    "doc = nlp(\"I have a golden retriever\")\n",
    "\n",
    "for match_id, start, end in matcher(doc):\n",
    "    span = doc[start:end]\n",
    "    print('Matched span:', span.text)\n",
    "    print('Root token:', span.root.text)\n",
    "    print('Root head token:', span.root.head.text)\n",
    "    print('Previous token:', doc[start - 1].text, doc[start - 1].pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = nlp(\"Golden Retriever\")\n",
    "matcher.add('DOG', None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"I have a Golden Retriever\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched Span:  Golden Retriever\n",
      "Start: 3\n",
      "End: 5\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matcher(doc):\n",
    "    span = doc[start:end]\n",
    "    print('Matched Span: ', span.text)\n",
    "    print('Start:', start)\n",
    "    print('End:', end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x1cdbb5deba8>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x1cdbb7d56a8>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x1cdbb7d5708>)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_component(doc):\n",
    "    print('Doc Length:', len(doc))\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(custom_component, first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: ['custom_component', 'tagger', 'parser', 'ner']\n"
     ]
    }
   ],
   "source": [
    "print('Pipeline:', nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc, Token, Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc.set_extension('title', default=None)\n",
    "Token.set_extension('is_color', default=False)\n",
    "Span.set_extension('has_color', default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc._.title = 'My Document'\n",
    "token._.is_color = True\n",
    "span._.has_color = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc Length: 5\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"The sky is blue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc[3]._.is_color = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[3]._.is_color "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_is_color(token):\n",
    "    colors = ['red', 'green', 'blue']\n",
    "    return token.text  in colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "Token.set_extension('is_color', force=True, getter=get_is_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc Length: 5\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"The sky is blue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True - blue\n"
     ]
    }
   ],
   "source": [
    "print(doc[3]._.is_color, '-', doc[3].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_has_color(span):\n",
    "    colors = ['red', 'yellow', 'blue']\n",
    "    return any(token.text in colors for token in span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "Span.set_extension('has_color', force=True, getter=get_has_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc Length: 5\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"The sky is blue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True - sky is blue\n",
      "False - The sky\n"
     ]
    }
   ],
   "source": [
    "print(doc[1:4]._.has_color, '-', doc[1:4].text)\n",
    "print(doc[0:2]._.has_color, '-', doc[0:2].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_token(doc, token_text):\n",
    "    in_doc = token_text in [token.text for token in doc]\n",
    "    return in_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc.set_extension('has_token', force=True, method=has_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc Length: 4\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"The sky is blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True - blue\n",
      "False - cloud\n"
     ]
    }
   ],
   "source": [
    "print(doc._.has_token('blue'), '- blue')\n",
    "print(doc._.has_token('cloud'), '- cloud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOTS_OF_TEXTS = \"\"\"I walked through the door with you, the air was cold,\n",
    "But something 'bout it felt like home somehow and I\n",
    "Left my scarf there at your sister's house,\n",
    "And you still got it in your drawer even now.\n",
    "Oh, your sweet disposition and my wide-eyed gaze.\n",
    "We're singing in the car, getting lost upstate.\n",
    "The Autumn leaves falling down like pieces into place,\n",
    "And I can picture it after all these days.\n",
    "And I know it's long gone,\n",
    "And that magic's not here no more,\n",
    "And I might be okay,\n",
    "But I'm not fine at all.\n",
    "'Cause there we are again on that little town street.\n",
    "You almost ran the red 'cause you were looking over me.\n",
    "Wind in my hair, I was there, I remember it all too well.\n",
    "Photo album on the counter, your cheeks were turning red.\n",
    "You used to be a little kid with glasses in a twin-size bed\n",
    "And your mother's telling stories about you on a tee ball team\n",
    "You tell me 'bout your past, thinking your future was me.\n",
    "And I know it's long gone\n",
    "And there was nothing else I could do\n",
    "And I forget about you long enough\n",
    "To forget why I needed to\n",
    "'Cause there we are again in the middle of the night.\n",
    "We dance around the kitchen in the refrigerator light\n",
    "Down the stairs, I was there, I remember it all too well, yeah.\n",
    "Maybe we got lost in translation, maybe I asked for too much,\n",
    "And maybe this thing was a masterpiece 'til you tore it all up.\n",
    "Running scared, I was there, I remember it all too well.\n",
    "Hey, you call me up again just to break me like a promise.\n",
    "So casually cruel in the name of being honest.\n",
    "I'm a crumpled up piece of paper lying here\n",
    "'Cause I remember it all, all, all too well.\n",
    "Time won't fly, it's like I'm paralyzed by it\n",
    "I'd like to be my old self again, but I'm still trying to find it\n",
    "After plaid shirt days and nights when you made me your own\n",
    "Now you mail back my things and I walk home alone\n",
    "But you keep my old scarf from that very first week\n",
    "'Cause it reminds you of innocence and it smells like me\n",
    "You can't get rid of it, 'cause you remember it all too well, yeah\n",
    "'Cause there we are again, when I loved you so\n",
    "Back before you lost the one real thing you've ever known\n",
    "It was rare, I was there, I remember it all too well\n",
    "Wind in my hair, you were there, you remember it all\n",
    "Down the stairs, you were there, you remember it all\n",
    "It was rare, I was there, I remember it all too well\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad way\n",
    "# docs = [nlp(text) for text in LOTS_OF_TEXTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfect way\n",
    "# docs = list(nlp.pipe(LOTS_OF_TEXTS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-7b98bbb0a577>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    ('This is a text', {'id': 1, 'page_number': 15}),\n",
    "    ('Add another text', {'id': 2, 'page_number': 16})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc, context in nlp.pipe(data, as_tuples=True):\n",
    "    print(doc.text, context['page_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc.set_extension('id', default=None)\n",
    "Doc.set_extension('page_number', default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc, context in nlp.pipe(data, as_tuples=True):\n",
    "    doc._.id = context['id']\n",
    "    doc._.page_number = context['page_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp.make_doc(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computationally expensive way\n",
    "doc = nlp(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computationally easier, sometimes a better way\n",
    "doc = nlp.make_doc(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc Length: 17\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    " with nlp.disable_pipes('tagger', 'parser'):\n",
    "        doc = nlp('Hello World, I am Aditya. I have an idea which Neuralink Ltd. is executing.')\n",
    "        print([token.pos_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc Length: 17\n",
      "['INTJ', 'PROPN', 'PUNCT', 'PRON', 'AUX', 'PROPN', 'PUNCT', 'PRON', 'AUX', 'DET', 'NOUN', 'PRON', 'PROPN', 'PROPN', 'AUX', 'VERB', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Hello World, I am Aditya. I have an idea which Neuralink Ltd. is executing.')\n",
    "print([token.pos_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
